{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h6wxlrA6p9g",
        "outputId": "ed6d8651-3b80-445d-ab1e-bc9beb6492c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: be-great in /opt/conda/envs/llm/lib/python3.10/site-packages (0.0.7)\n",
            "Requirement already satisfied: datasets in /opt/conda/envs/llm/lib/python3.10/site-packages (2.14.6)\n",
            "Requirement already satisfied: transformers in /opt/conda/envs/llm/lib/python3.10/site-packages (4.34.1)\n",
            "Requirement already satisfied: trl in /opt/conda/envs/llm/lib/python3.10/site-packages (0.8.6)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sdmetric (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sdmetric\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install be-great datasets transformers trl sdmetric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhWrM5yCYS21"
      },
      "source": [
        "## Step 0: load dataset\n",
        "\n",
        "First we load the table we want to synthesize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBDxiXd9Pqv",
        "outputId": "6895e37a-a401-4a1e-c625-bce703a6c26b"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N72uHAKe9lKm"
      },
      "outputs": [],
      "source": [
        "#data_path = \"/content/gdrive/MyDrive/stats261/ctr_subset.csv\"\n",
        "data_path = \"ctr_subset_imbalanced.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GlgwmbSL-JQY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(data_path,index_col=0)\n",
        "real_columns = data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YjUH_pxfYVAV"
      },
      "outputs": [],
      "source": [
        "# Adjust order of columns to make target label the last\n",
        "labels = data.pop('label')\n",
        "data['label'] = labels\n",
        "\n",
        "imbalanced_data = data.sample(5546, random_state=42)\n",
        "\n",
        "train, test = train_test_split(imbalanced_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "1    2773\n",
              "0    2773\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imbalanced_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "imbalanced_data.to_csv(\"ctrTaskImbalanced.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIIaL3X386HB",
        "outputId": "b0ef44e2-d3cb-4bee-ce45-4a30f9efbe0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5546, 24) Index(['age', 'residence', 'city', 'series_dev', 'series_group', 'emui_dev',\n",
            "       'device_name', 'device_size', 'slot_id', 'pt_d', 'u_refreshTimes_x',\n",
            "       'u_feedLifeCycle_x', 'u_browserLifeCycle', 'u_browserMode',\n",
            "       'u_feedLifeCycle_y', 'u_refreshTimes_y', 'i_cat', 'i_dislikeTimes',\n",
            "       'i_upTimes', 'e_m', 'e_po', 'e_pl', 'user_id', 'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(imbalanced_data.shape, imbalanced_data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSlw-P7NYHIy"
      },
      "source": [
        "## Step 1: supervised-finetuning for table generation\n",
        "\n",
        "In this step, we finetune a distillgpt2 model to perform synthetic table generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "w5zPcP2vYGog",
        "outputId": "ce060eac-b32e-4b70-9c78-d5a1cc7a1469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from be_great import GReaT\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "duration = 500\n",
        "max_seq_len = 500\n",
        "\n",
        "trained_checkpoint = None\n",
        "#trained_checkpoint = \"./great_checkpoint\"\n",
        "\n",
        "model_great = GReaT(llm='distilgpt2', batch_size=32,  epochs=duration, fp16=True,save_steps=30000)\n",
        "if trained_checkpoint is not None:\n",
        "    model_great.load_from_dir(trained_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='154' max='69500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  154/69500 00:41 < 5:13:52, 3.68 it/s, Epoch 1.10/500]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_great.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = model_great.model\n",
        "base_model.save_pretrained(\"./trained_base_model_imbalanced\")\n",
        "model_great.save(\"./great_checkpoint_imbalanced\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "451it [00:11, 38.85it/s]                         \n"
          ]
        }
      ],
      "source": [
        "synthetic_data = model_great.sample(n_samples=len(train),max_length=max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "synthetic_data.to_csv(\"ctrTaskImbalanced_GReaT_default_5546.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vrgAcTLYyU9"
      },
      "source": [
        "## Step 2: reward model training\n",
        "\n",
        "Our reward model is a powerful classifier trained on the real tabular data. We apply it on synthetic table rows, and the reward is maximize when the distance between synthetic and predicted class probabilities are minimized. The idea is that the synthetic data should preserved the feature-target relationship as found in the real data, by powerful classsifiers such as XGboost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic4mtv_JY1Rd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        97\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.48      0.50      0.49       100\n",
            "weighted avg       0.94      0.97      0.96       100\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "X_train, X_test = train.iloc[:, :-1], test.iloc[:, :-1]\n",
        "y_train, y_test = train.iloc[:, -1],  test.iloc[:, -1]  # assume y is already encoded as 0 and 1\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "# Define the model and preprocessors\n",
        "classifier = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', classifier)])\n",
        "\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation as sanity check\n",
        "y_pred = pipeline.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthetic Accuracy: 0.97\n",
            "Synthetic Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        97\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.48      0.50      0.49       100\n",
            "weighted avg       0.94      0.97      0.96       100\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Now try fitting a model from synthetic data and evaluate on test set\n",
        "x_synth, y_synth = synthetic_data.iloc[:, :-1],synthetic_data.iloc[:, -1]\n",
        "\n",
        "classifier_synth = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "pipeline_synth = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', classifier_synth)])\n",
        "pipeline_synth.fit(x_synth, y_synth)\n",
        "y_pred = pipeline_synth.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Synthetic Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Synthetic Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzfTRB1WZ6IH"
      },
      "source": [
        "## Step 3: reward finetuning\n",
        "\n",
        "Now we define a reward function that does the following\n",
        "\n",
        "\n",
        "1.   Given a generated text, reverse it back to a table row.\n",
        "2.   Use the pre-trained classifier to predict its target based generated features.\n",
        "3.   Given the distance between predicted and synthetic targets, calculate its reward.\n",
        "\n",
        "Then we finetune the model trained above in PPO setting.\n",
        "\n",
        "Cross check to see if PPO and RL work correctly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQdbycVto_DN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from be_great.great_utils import _convert_text_to_tabular_data, _convert_tokens_to_text\n",
        "\n",
        "\n",
        "def calcualte_reward(synth_data, classifier, preprocessor):\n",
        "    X_synth = synth_data.iloc[:, :-1]\n",
        "    y_synth = synth_data.iloc[:, -1]\n",
        "\n",
        "    # Apply preprocessing pipeline\n",
        "    #print(X_synth)\n",
        "    X_synth_transformed = preprocessor.transform(X_synth)\n",
        "\n",
        "    # Get predicted class probabilities\n",
        "    y_pred_proba = classifier.predict_proba(X_synth_transformed)[:, 1]\n",
        "\n",
        "    rewards = 1 - np.abs(y_pred_proba - y_synth)\n",
        "\n",
        "    # Format rewards for PPO trainer\n",
        "    # the PPO trainer expects a list of tensors\n",
        "    return [torch.tensor(r) for r in rewards]\n",
        "\n",
        "# Custom reward function\n",
        "def reward_function(output_text, clasifier, preprocessor, columns, num_cols):\n",
        "    # Replace with your actual reward computation logic\n",
        "    synth_data = _convert_text_to_tabular_data(output_text, columns)\n",
        "    # Remove rows where we have not generated anything\n",
        "    synth_data = synth_data[~(synth_data == \"placeholder\").any(axis=1)]\n",
        "\n",
        "    # Remove rows where all values are NaN\n",
        "    synth_data = synth_data.dropna(how=\"all\")\n",
        "\n",
        "    # Remove rows with flawed numerical values but keep NaNs\n",
        "    #print(len(num_cols), synth_data.shape)\n",
        "    for i_num_cols in num_cols:\n",
        "        coerced_series = pd.to_numeric(\n",
        "            synth_data[i_num_cols], errors=\"coerce\"\n",
        "        )\n",
        "        synth_data = synth_data[\n",
        "            coerced_series.notnull() | synth_data[i_num_cols].isna()\n",
        "        ]\n",
        "\n",
        "    # Convert numerical columns to float\n",
        "    synth_data[num_cols] = synth_data[num_cols].astype(float)\n",
        "    if len(synth_data) > 0:\n",
        "        return calcualte_reward(synth_data, clasifier, preprocessor)\n",
        "    else:\n",
        "        return [torch.tensor(0.0, dtype=torch.float32)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTpKJsBgtRSa"
      },
      "outputs": [],
      "source": [
        "def df_to_string_list(df):\n",
        "    string_list = []\n",
        "    for _, row in df.iterrows():\n",
        "        row_string = \", \".join([f\"{col} is {val}\" for col, val in row.items()])\n",
        "        string_list.append(row_string)\n",
        "    return string_list\n",
        "\n",
        "def df_cells_to_string_list(df):\n",
        "    cell_string_list = []\n",
        "    for col in df.columns:\n",
        "        for val in df[col]:\n",
        "            cell_string_list.append(f\"{col} is {val}\")\n",
        "    return cell_string_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEeOHfCl6JbO"
      },
      "outputs": [],
      "source": [
        "df_text = df_to_string_list(synthetic_data)\n",
        "\n",
        "# Test reconstruction of table from text\n",
        "rewards = reward_function(df_text, classifier, preprocessor, real_columns, list(numerical_features)+[real_columns[-1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2aBWGqiZ9Bl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from trl import PPOTrainer, PPOConfig\n",
        "from trl.models.modeling_value_head import AutoModelForCausalLMWithValueHead\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "llm = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm, padding_side='left')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load the trained base model into AutoModelForCausalLMWithValueHead\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"./great_checkpoint_imbalanced\")\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Define dataset. Use different columns as condition to improve diversity\n",
        "dataset = CustomDataset(df_cells_to_string_list(train))\n",
        "batch_size = 32\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define PPO Configuration\n",
        "ppo_config = PPOConfig(\n",
        "    model_name=llm,\n",
        "    learning_rate=1e-5,  # Slightly increased learning rate\n",
        "    batch_size=batch_size,\n",
        "    ppo_epochs=10,\n",
        "    mini_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        ")\n",
        "\n",
        "# Initialize the PPO Trainer\n",
        "ppo_trainer = PPOTrainer(\n",
        "    config=ppo_config,\n",
        "    model=model,\n",
        "    ref_model=None,  # Reference model\n",
        "    tokenizer=tokenizer,\n",
        "    dataset=dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSrnaev_g1XM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/4, Average Reward: 0.023404892534017563\n",
            "Epoch: 2/4, Average Reward: 0.0\n",
            "Epoch: 3/4, Average Reward: 0.0\n",
            "Epoch: 4/4, Average Reward: 0.0\n",
            "PPO training completed!\n"
          ]
        }
      ],
      "source": [
        "# PPO Training loop\n",
        "\n",
        "#https://huggingface.co/docs/trl/main/en/ppo_trainer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for epoch in range(ppo_config.ppo_epochs):\n",
        "    epoch_rewards = []\n",
        "\n",
        "    for batch in data_loader:\n",
        "        try:\n",
        "            # Tokenize inputs and move to device\n",
        "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "            input_ids = inputs['input_ids'].to(device)\n",
        "\n",
        "            # Generate outputs from the model\n",
        "            # Set max_length to the desired length of the generated text\n",
        "            max_length = 300  # Adjust as needed for your application\n",
        "            generated_ids = model.generate(input_ids, max_length=max_length, do_sample=True,temperature=0.70, pad_token_id=50256)\n",
        "\n",
        "            generated_texts = [tokenizer.decode(generated_ids[i], skip_special_tokens=True) for i in range(generated_ids.size(0))]\n",
        "\n",
        "            rewards = [reward_function([generated_text], classifier, preprocessor, real_columns, list(numerical_features)+[real_columns[-1]]) for generated_text in generated_texts]\n",
        "\n",
        "            rewards = [item for sublist in rewards for item in sublist]\n",
        "\n",
        "            epoch_rewards.extend(rewards)\n",
        "\n",
        "            queries = [input_ids[i] for i in range(input_ids.size(0))]\n",
        "            responses = [generated_ids[i] for i in range(generated_ids.size(0))]\n",
        "            rewards = [reward.clone().detach() for reward in rewards]\n",
        "\n",
        "            ppo_trainer.step(queries, responses, rewards)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    avg_reward = torch.mean(torch.stack(epoch_rewards)).item()\n",
        "    print(f\"Epoch: {epoch+1}/{ppo_config.ppo_epochs}, Average Reward: {avg_reward}\")\n",
        "\n",
        "print(\"PPO training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_directory = \"RL_trained_imbalanced\"\n",
        "model.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu25Eastzwwp"
      },
      "source": [
        "## Step 4 (TODO)\n",
        "\n",
        "Finally we load the trained parameters back to GReaT model, generate synthetic data, train another XGBoost on new synthtic data and observe changes its utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at RL_trained_500imbalanced were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Run this cell if we are returning after RL training.\n",
        "save_directory = \"RL_trained_imbalanced\"\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(save_directory)\n",
        "\n",
        "llm = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm, padding_side='left')\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za5h7cGl8LaZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "456it [00:11, 39.66it/s]                         \n"
          ]
        }
      ],
      "source": [
        "model_great.parameters = model.parameters\n",
        "new_synthetic_data = model_great.sample(n_samples=len(train),max_length=duration)\n",
        "\n",
        "new_df_text = df_to_string_list(new_synthetic_data)\n",
        "\n",
        "new_rewards = reward_function(df_text, classifier, preprocessor, real_columns, list(numerical_features)+[real_columns[-1]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_synthetic_data.to_csv(\"ctrTaskImbalanced_GReaTRL_default_5546.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.97\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        97\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.97       100\n",
            "   macro avg       0.48      0.50      0.49       100\n",
            "weighted avg       0.94      0.97      0.96       100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_synth_new, y_synth_new = new_synthetic_data.iloc[:,:-1], new_synthetic_data.iloc[:,-1]\n",
        "\n",
        "classifier_synth = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "pipeline_synth = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', classifier_synth)])\n",
        "\n",
        "pipeline_synth.fit(x_synth_new, y_synth_new)\n",
        "y_pred = pipeline_synth.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "# Evaluation as sanity check\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>residence</th>\n",
              "      <th>city</th>\n",
              "      <th>series_dev</th>\n",
              "      <th>series_group</th>\n",
              "      <th>emui_dev</th>\n",
              "      <th>device_name</th>\n",
              "      <th>device_size</th>\n",
              "      <th>slot_id</th>\n",
              "      <th>pt_d</th>\n",
              "      <th>...</th>\n",
              "      <th>u_feedLifeCycle_y</th>\n",
              "      <th>u_refreshTimes_y</th>\n",
              "      <th>i_cat</th>\n",
              "      <th>i_dislikeTimes</th>\n",
              "      <th>i_upTimes</th>\n",
              "      <th>e_m</th>\n",
              "      <th>e_po</th>\n",
              "      <th>e_pl</th>\n",
              "      <th>user_id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>2032.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2420.0</td>\n",
              "      <td>196194.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>1975.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1074.0</td>\n",
              "      <td>192576.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>2438.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1933.0</td>\n",
              "      <td>168365.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>1186.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1481.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>667.0</td>\n",
              "      <td>177291.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>1555.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022061e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1278.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2393.0</td>\n",
              "      <td>121121.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>7.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>2204.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022061e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2683.0</td>\n",
              "      <td>270808.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>3.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1555.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022061e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2305.0</td>\n",
              "      <td>157627.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>2117.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1207.0</td>\n",
              "      <td>120180.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>7.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>2469.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022060e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>308.0</td>\n",
              "      <td>207378.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>3.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>1078.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.022061e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>120139.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  residence   city  series_dev  series_group  emui_dev  device_name  \\\n",
              "0    7.0       46.0  354.0        16.0           5.0      20.0        346.0   \n",
              "1    5.0       21.0  424.0        19.0           6.0      16.0        192.0   \n",
              "2    3.0       21.0  391.0        11.0           8.0      29.0        248.0   \n",
              "3    8.0       33.0  319.0        16.0           5.0      20.0        334.0   \n",
              "4    2.0       16.0  391.0        34.0           7.0      20.0        191.0   \n",
              "..   ...        ...    ...         ...           ...       ...          ...   \n",
              "395  7.0       27.0  162.0        16.0           5.0      20.0        240.0   \n",
              "396  3.0       26.0  158.0        23.0           6.0      19.0        156.0   \n",
              "397  8.0       20.0  167.0        31.0           3.0      20.0        346.0   \n",
              "398  7.0       23.0  262.0        30.0           3.0      28.0        278.0   \n",
              "399  3.0       39.0  429.0        11.0           8.0      29.0        338.0   \n",
              "\n",
              "     device_size  slot_id          pt_d  ...  u_feedLifeCycle_y  \\\n",
              "0         2032.0     16.0  2.022060e+11  ...               17.0   \n",
              "1         1975.0     16.0  2.022060e+11  ...               17.0   \n",
              "2         2438.0     17.0  2.022060e+11  ...               11.0   \n",
              "3         1186.0     16.0  2.022060e+11  ...               17.0   \n",
              "4         1555.0     16.0  2.022061e+11  ...               17.0   \n",
              "..           ...      ...           ...  ...                ...   \n",
              "395       2204.0     16.0  2.022061e+11  ...               16.0   \n",
              "396       1555.0     16.0  2.022061e+11  ...               17.0   \n",
              "397       2117.0     22.0  2.022060e+11  ...               17.0   \n",
              "398       2469.0     16.0  2.022060e+11  ...               17.0   \n",
              "399       1078.0     16.0  2.022061e+11  ...               17.0   \n",
              "\n",
              "     u_refreshTimes_y  i_cat  i_dislikeTimes  i_upTimes     e_m  e_po    e_pl  \\\n",
              "0                 9.0    0.0             0.0        9.0   740.0   6.0  2420.0   \n",
              "1                 8.0  219.0             0.0        9.0   620.0   7.0  1074.0   \n",
              "2                 0.0   86.0             0.0        9.0    73.0   6.0  1933.0   \n",
              "3                 9.0   98.0             0.0        0.0  1481.0   6.0   667.0   \n",
              "4                 6.0   98.0             0.0        9.0  1278.0   6.0  2393.0   \n",
              "..                ...    ...             ...        ...     ...   ...     ...   \n",
              "395               0.0   98.0             0.0        0.0   335.0   6.0  2683.0   \n",
              "396               8.0   98.0             0.0        0.0  1089.0   6.0  2305.0   \n",
              "397               0.0   98.0             0.0        9.0   565.0   6.0  1207.0   \n",
              "398               7.0  168.0             0.0        9.0   506.0   6.0   308.0   \n",
              "399               7.0   98.0             0.0        0.0  1290.0   7.0    74.0   \n",
              "\n",
              "      user_id  label  \n",
              "0    196194.0    0.0  \n",
              "1    192576.0    0.0  \n",
              "2    168365.0    0.0  \n",
              "3    177291.0    0.0  \n",
              "4    121121.0    0.0  \n",
              "..        ...    ...  \n",
              "395  270808.0    0.0  \n",
              "396  157627.0    0.0  \n",
              "397  120180.0    0.0  \n",
              "398  207378.0    0.0  \n",
              "399  120139.0    0.0  \n",
              "\n",
              "[400 rows x 24 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_synthetic_data"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
