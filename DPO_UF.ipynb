{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h6wxlrA6p9g",
        "outputId": "ed6d8651-3b80-445d-ab1e-bc9beb6492c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: be-great in /opt/conda/envs/llm/lib/python3.10/site-packages (0.0.7)\n",
            "Requirement already satisfied: datasets in /opt/conda/envs/llm/lib/python3.10/site-packages (2.14.6)\n",
            "Requirement already satisfied: transformers in /opt/conda/envs/llm/lib/python3.10/site-packages (4.34.1)\n",
            "Requirement already satisfied: trl in /opt/conda/envs/llm/lib/python3.10/site-packages (0.9.6.dev0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sdmetric (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sdmetric\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install be-great datasets transformers trl sdmetric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhWrM5yCYS21"
      },
      "source": [
        "## Step 0: load dataset\n",
        "\n",
        "First we load the table we want to synthesize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBDxiXd9Pqv",
        "outputId": "6895e37a-a401-4a1e-c625-bce703a6c26b"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N72uHAKe9lKm"
      },
      "outputs": [],
      "source": [
        "data_path = \"csv/wilt.csv\"\n",
        "#data_path = \"ChurnModeling.csv\"\n",
        "#data_path = \"iris.csv\"\n",
        "data_name = data_path.replace(\".csv\", \"\").replace(\"csv/\", \"\")\n",
        "test_idx = 500 # signals 0.5 split ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GlgwmbSL-JQY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(data_path)\n",
        "target = data.columns[-1]\n",
        "#num_sample = min(500, len(data))\n",
        "num_sample = None\n",
        "if num_sample is not None:\n",
        "    data = data.sample(num_sample, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "balanced_data = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIIaL3X386HB",
        "outputId": "b0ef44e2-d3cb-4bee-ce45-4a30f9efbe0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4839, 6) Index(['GLCM_Pan', 'Mean_G', 'Mean_R', 'Mean_NIR', 'SD_Plan', 'class'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(balanced_data.shape, balanced_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, test = train_test_split(balanced_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSlw-P7NYHIy"
      },
      "source": [
        "## Step 1: supervised-finetuning for table generation\n",
        "\n",
        "In this step, we finetune a distillgpt2 model to perform synthetic table generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "w5zPcP2vYGog",
        "outputId": "ce060eac-b32e-4b70-9c78-d5a1cc7a1469"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from be_great import GReaT\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "duration = 500\n",
        "max_seq_len = 150\n",
        "\n",
        "trained_checkpoint = None\n",
        "#trained_checkpoint = \"./great_checkpoint_ctrBalanced500_100\"\n",
        "\n",
        "model_great = GReaT(llm='gpt2', batch_size=32,  epochs=duration, fp16=True,save_steps=30000)\n",
        "if trained_checkpoint is not None:\n",
        "    model_great.load_from_dir(trained_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='79' max='60500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   79/60500 00:11 < 2:31:04, 6.67 it/s, Epoch 0.64/500]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if trained_checkpoint is None:\n",
        "    model_great.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/be_great/great.py:430: UserWarning: Directory ./great_checkpoint_census1000_100 already exists and is overwritten now.\n",
            "  warnings.warn(f\"Directory {path} already exists and is overwritten now.\")\n"
          ]
        }
      ],
      "source": [
        "model_great.save(f\"checkpoints/great_checkpoint_{data_name}_{test_idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = model_great.model\n",
        "base_model.save_pretrained(f\"checkpoints/trained_base_model_{data_name}_{test_idx}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "406it [00:08, 48.60it/s]                         \n"
          ]
        }
      ],
      "source": [
        "synthetic_data = model_great.sample(n_samples=len(train),max_length=max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "synthetic_data.to_csv(f\"synth_data/{data_name}_GReaT_default_{test_idx}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vrgAcTLYyU9"
      },
      "source": [
        "## Step 2: Create DPO Dataset\n",
        "\n",
        "A DPO-compatible dataset should have 3 entries: prompt, chosen, rejected.\n",
        "\n",
        "We select the conditional columns from real rows as our prompt. For chosen set we use the corresponding real columns; for rejected set: 1, if the target is not in the prompt, then we alter the target value in the chosen set to create a rejected set with \"wrong\" target value, which should be less favorable, 2 if the target is in the prompt, then we replace all values in the chosen set with values from a row with different target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic4mtv_JY1Rd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, DatasetDict\n",
        "import random\n",
        "\n",
        "def create_perturbed_dataset(df, target, p):\n",
        "    random.seed(42)  # For reproducibility\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    data = []\n",
        "\n",
        "    all_unique_categories = df[target].unique()\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        # Perturb the order of cells\n",
        "        shuffled_row = row.sample(frac=1)\n",
        "        #print(shuffled_row)\n",
        "        \n",
        "        # Determine split index\n",
        "        split_idx = int(p * len(shuffled_row))\n",
        "        \n",
        "        # Split into prompt and chosen sets\n",
        "        prompt_set = shuffled_row[:split_idx]\n",
        "        chosen_set = shuffled_row[split_idx:]\n",
        "        \n",
        "        if target in chosen_set.index:\n",
        "            # If target is in chosen set\n",
        "            chosen_target_value = chosen_set[target]\n",
        "            # Change the category of the target column to create the rejected set\n",
        "            different_categories = all_unique_categories[all_unique_categories != chosen_target_value]\n",
        "            rejected_target_value = np.random.choice(different_categories)\n",
        "            rejected_set = chosen_set.copy()\n",
        "            rejected_set[target] = rejected_target_value\n",
        "        else:\n",
        "            # If target is in prompt set\n",
        "            chosen_target_value = prompt_set[target]\n",
        "            # Sample another row with different target classes\n",
        "            other_rows = df[df[target] != chosen_target_value].sample(1, random_state=42)\n",
        "            rejected_set = chosen_set.copy()\n",
        "            for col in rejected_set.index:\n",
        "                if col != target:\n",
        "                    rejected_set[col] = other_rows.iloc[0][col]\n",
        "        \n",
        "        # Convert to strings\n",
        "        prompt_str = \", \".join([f\"{col} is {val}\" for col, val in prompt_set.items()])\n",
        "        chosen_str = \", \".join([f\"{col} is {val}\" for col, val in chosen_set.items()])\n",
        "        rejected_str = \", \".join([f\"{col} is {val}\" for col, val in rejected_set.items()])\n",
        "        \n",
        "        data.append({\n",
        "            \"prompt\": prompt_str,\n",
        "            \"chosen\": chosen_str,\n",
        "            \"rejected\": rejected_str\n",
        "        })\n",
        "    \n",
        "    # Create a HuggingFace dataset\n",
        "    dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'chosen', 'rejected'],\n",
            "    num_rows: 400\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "split_ratio = test_idx / 1000\n",
        "dataset = create_perturbed_dataset(train, target, split_ratio)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzfTRB1WZ6IH"
      },
      "source": [
        "## Step 3: DPO Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2aBWGqiZ9Bl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:394: UserWarning: `max_length` is not set in the DPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:407: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:442: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 400/400 [00:00<00:00, 932.13 examples/s]\n",
            "Map: 100%|██████████| 400/400 [00:00<00:00, 948.24 examples/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "from trl.models.modeling_value_head import AutoModelForCausalLMWithValueHead\n",
        "from trl import DPOTrainer,DPOConfig\n",
        "import torch\n",
        "\n",
        "llm = 'gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "base_model_path = f\"checkpoints/trained_base_model_{data_name}_{test_idx}\"\n",
        "beta = 0.1\n",
        "epochs = 3\n",
        "output_dir = f\"checkpoints/trained_dpo_model_{data_name}_{test_idx}\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_path # location of saved SFT model\n",
        ")\n",
        "model_ref = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_path\n",
        ")\n",
        "\n",
        "training_args = DPOConfig(\n",
        "    beta=beta,\n",
        "    output_dir=output_dir\n",
        ")\n",
        "\n",
        "dpo_trainer = DPOTrainer(\n",
        "    model,\n",
        "    model_ref,\n",
        "    args=training_args,\n",
        "    beta=beta,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset=dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 00:25, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=0.13053329467773436, metrics={'train_runtime': 25.8637, 'train_samples_per_second': 46.397, 'train_steps_per_second': 5.8, 'total_flos': 0.0, 'train_loss': 0.13053329467773436, 'epoch': 3.0})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dpo_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dpo_trainer.save_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu25Eastzwwp"
      },
      "source": [
        "## Step 4: Utility Evaluation\n",
        "\n",
        "Finally we load the trained parameters back to GReaT model, generate synthetic data, train another XGBoost on new synthtic data and observe changes its utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this cell if we are returning after RL training.\n",
        "model = AutoModelForCausalLM.from_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za5h7cGl8LaZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "401it [00:08, 48.52it/s]                         \n"
          ]
        }
      ],
      "source": [
        "model_great.parameters = model.parameters\n",
        "new_synthetic_data = model_great.sample(n_samples=len(train),max_length=duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_synthetic_data.to_csv(f\"synth_data/{data_name}_GReaTDPO_default_{test_idx}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def column_type_mapping(df):\n",
        "    type_mapping = {}\n",
        "    for column in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[column]):\n",
        "            type_mapping[column] = 'continuous'\n",
        "        else:\n",
        "            type_mapping[column] = 'categorical'\n",
        "    return type_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 13.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialing Evaluator...\n",
            "Fidelity Evaluation Module initialized\n",
            "Privacy Evaluation Module initialized\n",
            "Utility Evaluation Module initialized\n",
            "evaluated  SumStats\n",
            "Generating report ...\n",
            "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 2166.55it/s]\n",
            "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 70.51it/s]\n",
            "\n",
            "Overall Quality Score: 31.14%\n",
            "\n",
            "Properties:\n",
            "- Column Shapes: 43.78%\n",
            "- Column Pair Trends: 18.5%\n",
            "Generating report ...\n",
            "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 2398.48it/s]\n",
            "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 74.01it/s]\n",
            "\n",
            "Overall Quality Score: 30.54%\n",
            "\n",
            "Properties:\n",
            "- Column Shapes: 43.23%\n",
            "- Column Pair Trends: 17.85%\n",
            "evaluated  ColumnShape\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/interfaces/evaluation_interface.py\", line 36, in evaluate\n",
            "    metric_instance = self.metric_factory.create_instance(metric, self.real_data, self.synth_data, self.holdout_data, self.column_name_to_datatype, self.config)\n",
            "  File \"/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/factories/metric_factory.py\", line 29, in create_instance\n",
            "    return metric_class(real_data, synth_data, holdout_data, column_name_to_datatype, config)\n",
            "TypeError: ColumnShapeHoldout.__init__() takes from 4 to 5 positional arguments but 6 were given\n",
            "\n",
            "Metric ColumnShapeHoldout calculation failed! Skipping\n",
            "Target column is: income\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics = pd.concat([metrics, pd.DataFrame({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted real data!\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics = pd.concat([metrics, pd.DataFrame({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted synth data!\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  metrics = pd.concat([metrics, pd.DataFrame({\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted augmented data!\n",
            "evaluated  TabularUtility\n",
            "Plotting box plots\n",
            "Plotting  SumStats\n",
            "Plotting column shape\n",
            "Plotting  ColumnShape\n",
            "Plotting  TabularUtility\n",
            "Making report path at: report/census1000_GReaT_default_100\n",
            "Error converting  ColumnShape_real_table.csv  to csv\n",
            "Error converting  ColumnShape_synthetic_table.csv  to csv\n"
          ]
        }
      ],
      "source": [
        "from evaluator import *\n",
        "import os\n",
        "\n",
        "report_dir = \"report\"\n",
        "os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "config = {\"holdout_seed\":42, \"holdout_size\":0.2, 'target_column':target,\n",
        "        \"fidelity_metrics\": [\"SumStats\", \"ColumnShape\", \"ColumnShapeHoldout\"],\n",
        "    \"privacy_metrics\": [],\n",
        "    \"utility_metrics\": [\"TabularUtility\"],}\n",
        "column_name_to_datatype = column_type_mapping(balanced_data)\n",
        "\n",
        "save_path = f\"{report_dir}/{data_name}_GReaT_default_{test_idx}\"\n",
        "evaluation_pipeline = EvaluationPipeline(real_data=balanced_data, synth_data=synthetic_data, column_name_to_datatype=column_name_to_datatype, config=config, save_path=save_path)\n",
        "evaluation_pipeline.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialing Evaluator...\n",
            "Fidelity Evaluation Module initialized\n",
            "Privacy Evaluation Module initialized\n",
            "Utility Evaluation Module initialized\n",
            "evaluated  SumStats\n",
            "Generating report ...\n",
            "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 2072.97it/s]\n",
            "(2/2) Evaluating Column Pair Trends: :   0%|          | 0/105 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 68.22it/s]\n",
            "\n",
            "Overall Quality Score: 31.45%\n",
            "\n",
            "Properties:\n",
            "- Column Shapes: 44.33%\n",
            "- Column Pair Trends: 18.56%\n",
            "Generating report ...\n",
            "(1/2) Evaluating Column Shapes: : 100%|██████████| 15/15 [00:00<00:00, 2239.35it/s]\n",
            "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 105/105 [00:01<00:00, 72.25it/s]\n",
            "\n",
            "Overall Quality Score: 30.68%\n",
            "\n",
            "Properties:\n",
            "- Column Shapes: 43.52%\n",
            "- Column Pair Trends: 17.85%\n",
            "evaluated  ColumnShape\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/interfaces/evaluation_interface.py\", line 36, in evaluate\n",
            "    metric_instance = self.metric_factory.create_instance(metric, self.real_data, self.synth_data, self.holdout_data, self.column_name_to_datatype, self.config)\n",
            "  File \"/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/factories/metric_factory.py\", line 29, in create_instance\n",
            "    return metric_class(real_data, synth_data, holdout_data, column_name_to_datatype, config)\n",
            "TypeError: ColumnShapeHoldout.__init__() takes from 4 to 5 positional arguments but 6 were given\n",
            "\n",
            "Metric ColumnShapeHoldout calculation failed! Skipping\n",
            "Target column is: income\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning:\n",
            "\n",
            "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted real data!\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning:\n",
            "\n",
            "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted synth data!\n",
            "Fitting NaiveBayes\n",
            "Fitting KNeighbors\n",
            "Fitting DecisionTree\n",
            "Fitting RandomForest\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/llm/lib/python3.10/site-packages/evaluator/metrics/Utility.py:247: FutureWarning:\n",
            "\n",
            "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting XGBoost\n",
            "Fitting CatBoost\n",
            "Fitted augmented data!\n",
            "evaluated  TabularUtility\n",
            "Plotting box plots\n",
            "Plotting  SumStats\n",
            "Plotting column shape\n",
            "Plotting  ColumnShape\n",
            "Plotting  TabularUtility\n",
            "Making report path at: report/census1000_GReaTDPO_default_100\n",
            "Error converting  ColumnShape_real_table.csv  to csv\n",
            "Error converting  ColumnShape_synthetic_table.csv  to csv\n"
          ]
        }
      ],
      "source": [
        "# For RL-based data\n",
        "save_path = f\"{report_dir}/{data_name}_GReaTDPO_default_{test_idx}\"\n",
        "evaluation_pipeline = EvaluationPipeline(real_data=balanced_data, synth_data=new_synthetic_data, column_name_to_datatype=column_name_to_datatype, config=config, save_path=save_path)\n",
        "evaluation_pipeline.run_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare F1 scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pre = pd.read_csv(f\"{report_dir}/{data_name}_GReaT_default_{test_idx}/TabularUtility_synth.csv\")\n",
        "df_post = pd.read_csv(f\"{report_dir}/{data_name}_GReaTDPO_default_{test_idx}/TabularUtility_synth.csv\")\n",
        "\n",
        "print(df_pre['F1'].mean())\n",
        "print(df_post['F1'].mean())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
